import tensorflow as tf
import numpy as np
import time
from evaluator import ModelEvaluator
from model import BiLSTM_CNN, TemporalAttention, SpatialAttention
from ablation_models import SpatialOnlyModel, TemporalOnlyModel


def measure_detection_time(model, X_test):
    start_time = time.time()
    _ = model.predict(X_test)
    end_time = time.time()
    return (end_time - start_time) / len(X_test)


def print_model_results(name, metrics):
    print(f"\n=== {name} Results ===")
    print(f"Accuracy: {metrics['accuracy']:.4f}")
    print(f"F1-score: {metrics['f1']:.4f}")
    print(f"FPR: {metrics['fpr']:.4f}")
    print(f"FNR: {metrics['fnr']:.4f}")
    print(f"AUC: {metrics['auc']:.4f}")
    print(f"Running Time: {metrics['running_time']:.4f}s")

    print("\nConfusion Matrix:")
    print(metrics['confusion_matrix'])


def load_custom_model(model_path):
    """加载自定义模型"""
    custom_objects = {
        'BiLSTM_CNN': BiLSTM_CNN,
        'TemporalAttention': TemporalAttention,
        'SpatialAttention': SpatialAttention,
        'SpatialOnlyModel': SpatialOnlyModel,
        'TemporalOnlyModel': TemporalOnlyModel
    }

    with tf.keras.utils.custom_object_scope(custom_objects):
        return tf.keras.models.load_model(model_path)

if __name__ == "__main__":
    current_time = "2025-04-28 02:44:59"
    current_user = "TIANQIISGOOD"
    print(f"Execution Time (UTC): {current_time}")
    print(f"User: {current_user}")
    print("=" * 50)

    # 加载评估数据
    print("\nLoading evaluation data...")
    X_val = np.load('saved_data/X_val.npy')
    y_val = np.load('saved_data/y_val.npy')
    X_test = np.load('saved_data/X_test.npy')
    y_test = np.load('saved_data/y_test.npy')
    print("Data loaded successfully!")

    # 初始化评估器和结果字典
    evaluator = ModelEvaluator()
    results = {}

    try:
        # 定义模型配置
        model_configs = {
            'BiLSTM-CNN': {'custom': True},
            'CNN': {'custom': False},
            'BiLSTM': {'custom': False},
            'GRU': {'custom': False},
            'Spatial-Only': {'custom': True},
            'Temporal-Only': {'custom': True}
        }

        # 加载并评估所有模型
        for model_name, config in model_configs.items():
            print(f"\nEvaluating {model_name} model...")

            try:
                # 根据模型类型选择加载方式
                if config['custom']:
                    model = load_custom_model(f'saved_models/{model_name}')
                else:
                    model = tf.keras.models.load_model(f'saved_models/{model_name}')

                # 在测试集上评估
                results[model_name] = evaluator.evaluate(model, X_test, y_test)
                results[model_name]['detection_time'] = measure_detection_time(model, X_test)

                # 打印结果
                print_model_results(model_name, results[model_name])

            except Exception as e:
                print(f"Error evaluating {model_name}: {str(e)}")
                continue

        # 打印性能对比表
        print("\n=== Model Performance Comparison ===")
        print("{:<15} | {:<8} | {:<8} | {:<8} | {:<8} | {:<8} | {:<8}".format(
            "Model", "Accuracy", "F1", "FPR", "FNR", "AUC", "Time(s)"))
        print("-" * 80)
        for name, metrics in results.items():
            print("{:<15} | {:<8.4f} | {:<8.4f} | {:<8.4f} | {:<8.4f} | {:<8.4f} | {:<8.4f}".format(
                name,
                metrics['accuracy'],
                metrics['f1'],
                metrics['fpr'],
                metrics['fnr'],
                metrics['auc'],
                metrics['running_time']
            ))

        print("\n" + "=" * 50)
        print(f"Results generated at: {current_time} UTC")
        print(f"Generated by: {current_user}")

    except Exception as e:
        print(f"评估过程中发生错误: {str(e)}")
        import traceback

        print(traceback.format_exc())
        print(f"Error occurred at: {current_time} UTC")
        print(f"User: {current_user}")